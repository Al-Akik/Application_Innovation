{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a18f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60679ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_data = open('donnees_appr_dev/test.xml', 'r').read()  # Read file\n",
    "root = ET.XML(xml_data)  # Parse XML\n",
    "\n",
    "data_train = []\n",
    "cols = []\n",
    "for i, child in enumerate(root):\n",
    "    data_train.append([subchild.text for subchild in child])\n",
    "\n",
    "df = pd.DataFrame(data_train)\n",
    "df.columns = ['movie','review_id','name','user_id','note','commentaire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54781c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"complete_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda66bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame()\n",
    "g['note'] = df['note'].replace(',','.')\n",
    "for i in range(len(df)):\n",
    "    g['note'][i] = g['note'][i].replace(',', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note']=g['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b66957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note'] = df['note'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer des notes de leurs forme à la forme [0,1,2,3,4,5,6,7,8,9]\n",
    "df['note'] = df['note'].apply(lambda note: int((note * 2)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebf626",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = \"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f76a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentaire'] = df['commentaire'].str.replace(url_regex, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ea0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for i in range(len(df)):\n",
    "    if df['commentaire'].iloc[i] != df['commentaire'].iloc[i] or df['commentaire'].iloc[i] == '' or df['commentaire'].iloc[i] == None :\n",
    "        to_remove.append(i)\n",
    "df.drop(index=to_remove,inplace=True)\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6525857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def text_has_emoji(text):\n",
    "    for character in text:\n",
    "        if character in emoji.EMOJI_DATA:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba503b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''to_remove = []\n",
    "for i in range(len(df)):\n",
    "    if text_has_emoji(df['commentaire'].iloc[i]):\n",
    "        to_remove.append(i)\n",
    "df.drop(index=to_remove,inplace=True)\n",
    "df.reset_index()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe985f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = ['140 dollars','3 pommes 4 oranges 1000023 poires ']\n",
    "output_string = [re.sub('(\\d+)', lambda m: num2words(m.group(),lang='fr'), sentence) for sentence in list_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11954c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c434210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = df['commentaire'].values.tolist()\n",
    "output_string = [re.sub('(\\d+)', lambda m: num2words(m.group(),lang='fr'), sentence) for sentence in list_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28137b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentaire'] = output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "  # Use a regular expression to remove all punctuation except the single quote character\n",
    "  text = re.sub(\"[%s]\" % re.escape(string.punctuation.replace(\"'\", \"\")), '', text)\n",
    "  return text\n",
    "\n",
    "text = \"This is a test sentence with punctuation. ' Can you help me modify the code?\"\n",
    "text = remove_punctuation(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5778b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43033c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"´\": \"'\", \"°\": \"\", \"€\": \"euros\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"pounds\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':'' ,'à':'a','â':'a','é':'e','è':'e','ê':'e',\n",
    "                 'ë':'e','ç':'c','î':'i','ï':'i','ô':'o','û':'u','ù':'u','ü':'u','ÿ':'y','æ':'ae','œ':'oe','À':'A',\n",
    "                'Â':'A','Ç':'C','É':'E','È':'E','Ê':'E','Ë':'E','Î':'I','Ï':'I','Ô':'O','Û':'U','Ù':'U','Ü':'U','Ÿ':'Y',\n",
    "                'Æ':'AE','Œ':'OE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c75d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Transformer les lettres de Majuscules en Minuscules\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r\"[^a-zA-ZàâçéèêëîïôûùüÿæœÀÂÇÉÈÊËÎÏÔÛÙÜŸÆŒ?.!,¿']+\", \" \", text) #garder pour ne pas enlever les charactères français\n",
    "    #text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text) # décommenter pour enlever les charactères français\n",
    "    return text\n",
    "def clean_contractions(text):\n",
    "    specials = [\"’\",\"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # commenter cette ligne pour garder les charactère français''\n",
    "    #text = re.sub(\"[%s]\" % re.escape(string.punctuation.replace(\"'\", \"\")), '', text)\n",
    "    # creation d'un espace entre un mot et une ponctuatuion qui le suit\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "def clean_special_chars(text, punct, mapping):  \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "def remove_space(text):  \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)\n",
    "'''def spellingCorrector(misspelled):\n",
    "    correction = []\n",
    "    misspelled = nltk.word_tokenize(misspelled)\n",
    "    for word in misspelled:\n",
    "        if re.search(r\"'\", word):\n",
    "            correction.append(word)\n",
    "        else:\n",
    "            corr = spell.correction(word)\n",
    "            if corr != None:\n",
    "                correction.append(corr)\n",
    "            else:\n",
    "                correction.append(word)\n",
    "    return ' '.join(correction)'''\n",
    "def text_preprocessing_pipeline(text):\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text)\n",
    "    #text = clean_special_chars(text, punct, punct_mapping) # décommenter pour enlever tous les ponctuations et \n",
    "    #charactères français\n",
    "    text = remove_space(text)\n",
    "    #text = spellingCorrector(text) # Computationellement forte de décommenter pas\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0810532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hj = df.commentaire.apply(lambda commentaire: ''.join(text_preprocessing_pipeline(commentaire)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d25e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentaire'] = df_hj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dev_complete_preprocessing_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,word in enumerate(stop):\n",
    "    stop[i] = text_preprocessing_pipeline(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66235ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstp = df['commentaire'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentaire'] = dfstp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word for word in df['commentaire'].iloc[0].split() if word not in (stop)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['commentaire'].apply(lambda x: len(str(x).split()))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.histplot(data=df, x='word_count')\n",
    "plt.title('Nombre de mots dans les commentaires')\n",
    "plt.xlabel('Nombre de mots')\n",
    "plt.ylabel('Nombre de commentaires')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Nombre de mots dans les commentaires.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = (sum(df['word_count'] < 360)/df.shape[0])*100\n",
    "print(\"Pourcentage d'articles ayant moins de 360 mots:{:.2f}%\".format(test_articles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
