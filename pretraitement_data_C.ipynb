{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eae352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_read_xml as pdx\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8efb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "xml_data = open('./train.xml', 'r', encoding = 'utf-8').read() \n",
    "root = ET.XML(xml_data)  \n",
    "\n",
    "data = []\n",
    "cols = []\n",
    "\n",
    "for i, child in enumerate(root):\n",
    "    data.append([subchild.text for subchild in child])\n",
    "    cols.append(child.tag)\n",
    "\n",
    "df_train = pd.DataFrame(data)  \n",
    "df_train.columns = ['movie', 'review_id', 'name','user_id','note','commentaire']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fe001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_data = open('./dev.xml', 'r', encoding = 'utf-8').read() \n",
    "root = ET.XML(xml_data)  \n",
    "data = []\n",
    "cols = []\n",
    "\n",
    "for i, child in enumerate(root):\n",
    "    data.append([subchild.text for subchild in child])\n",
    "    cols.append(child.tag)\n",
    "\n",
    "df_dev = pd.DataFrame(data)  \n",
    "df_dev.columns = ['movie', 'review_id', 'name','user_id','note','commentaire'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5256e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_data = open('./test.xml', 'r', encoding = 'utf-8').read() \n",
    "root = ET.XML(xml_data)  \n",
    "data = []\n",
    "cols = []\n",
    "\n",
    "for i, child in enumerate(root):\n",
    "    data.append([subchild.text for subchild in child])\n",
    "    cols.append(child.tag)\n",
    "\n",
    "df_test = pd.DataFrame(data)  \n",
    "df_test.columns = ['movie', 'review_id', 'name','user_id','commentaire'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import nltk\n",
    "from string import digits\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker(language='fr')\n",
    "tokenizer = nltk.RegexpTokenizer(r'''\\w'|\\w+|[^\\w\\s]''')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='french')\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b173ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlèvement des lignes manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f85b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = df_dev.isin(['',None,np.nan])\n",
    "lignes_Manquants = sd[sd.eq(True).any(1)]\n",
    "lignes_Manquants.index\n",
    "df_dev.drop(df_dev.index[lignes_Manquants.index],inplace = True)\n",
    "df_dev.index = range(df_dev.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = df_train.isin(['',None,np.nan])\n",
    "lignes_Manquants = sd[sd.eq(True).any(1)]\n",
    "lignes_Manquants.index\n",
    "df_train.drop(df_train.index[lignes_Manquants.index],inplace = True)\n",
    "df_train.index = range(df_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train)):\n",
    "    df_train['note'][i] = df_train['note'][i].replace(',', '.')# remplacer la virgule par point \n",
    "    \n",
    "for i in range(len(df_dev)):\n",
    "    df_dev['note'][i] = df_dev['note'][i].replace(',', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a189bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer les emojis avec de text\n",
    "for i in range(df_train.shape[0]):\n",
    "    if text_has_emoji(df_train['commentaire'].iloc[i]):\n",
    "        df_train['commentaire'][i] = emoji.demojize(df_train['commentaire'][i],language = 'fr')\n",
    "for i in range(df_dev.shape[0]):\n",
    "    if text_has_emoji(df_dev['commentaire'].iloc[i]):\n",
    "        df_dev['commentaire'][i] = emoji.demojize(df_dev['commentaire'][i],language = 'fr') \n",
    "        \n",
    "for i in range(df_test.shape[0]):\n",
    "    if text_has_emoji(df_test['commentaire'].iloc[i]):\n",
    "        df_test['commentaire'][i] = emoji.demojize(df_test['commentaire'][i],language = 'fr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad087ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#la tokénisation\n",
    "tokenized_sentences_train = []\n",
    "tokenized_sentences_dev = []\n",
    "tokenized_sentences_test = []\n",
    "tokenizer = nltk.RegexpTokenizer(r'''\\w'|\\w+|[^\\w\\s]''')\n",
    "for i in range(len(df_train)):\n",
    "    tokenized_sentences_train.append(tokenizer.tokenize(df_train['commentaire'][i]))\n",
    "    \n",
    "for i in range(len(df_dev)):\n",
    "    tokenized_sentences_dev.append(tokenizer.tokenize(df_dev['commentaire'][i]))\n",
    "    \n",
    "for i in range(len(df_train)):\n",
    "    tokenized_sentences_test.append(tokenizer.tokenize(df_test['commentaire'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6481e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construire une liste qui contient un ou deux caractères\n",
    "words_twochar = []\n",
    "for i in tokenized_sentences_train:\n",
    "    for j in i:\n",
    "        if len(j)<3:\n",
    "            words_twochar.append(j)\n",
    "            \n",
    "\n",
    "for i in tokenized_sentences_dev:\n",
    "    for j in i:\n",
    "        if len(j)<3:\n",
    "            words_twochar.append(j)\n",
    "\n",
    "\n",
    "for i in tokenized_sentences_test:\n",
    "    for j in i:\n",
    "        if len(j)<3:\n",
    "            words_twochar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#les stops words\n",
    "sw = set()\n",
    "ignore_words = ['?', '!',',','.',';','-','_']\n",
    "stop_words = nltk.corpus.stopwords.words('french')\n",
    "\n",
    "sw.update(ignore_words)\n",
    "sw.update(stop_words)\n",
    "sw.update(words_twochar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train)):\n",
    "    l_temp = []\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(df_train['commentaire'][i])\n",
    "        for item in tokens:\n",
    "            if item not in sw:\n",
    "                l_temp.append(item)\n",
    "        df_train['commentaire'][i] = \" \".join(l_temp)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    l_temp = []\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(df_test['commentaire'][i])\n",
    "        for item in tokens:\n",
    "            if item not in sw:\n",
    "                l_temp.append(item)\n",
    "        df_test['commentaire'][i] = \" \".join(l_temp)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "for i in range(len(df_dev)):\n",
    "    l_temp = []\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(df_dev['commentaire'][i])\n",
    "        for item in tokens:\n",
    "            if item not in sw:\n",
    "                l_temp.append(item)\n",
    "        df_dev['commentaire'][i] = \" \".join(l_temp)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_stem(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return [stemmer.stem(X.text) for X in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_clean(x):\n",
    "    x = str(x).lower().replace('\\\\', '').replace('_', ' ')\n",
    "    x = ps.cont_exp(x) \n",
    "    x = ps.remove_emails(x)\n",
    "    x = ps.remove_urls(x)\n",
    "    x = ps.remove_accented_chars(x)\n",
    "    x = ps.remove_special_chars(x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    x = \" \".join(return_stem(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaffdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_kgptalkie as ps #importation des pretraitement prêtes mais nous avons utilisé seulement celle qui marche sur la langue française aussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train)):\n",
    "    df_train['commentaire'][i] = get_clean(df_train['commentaire'][i])\n",
    "    \n",
    "for i in range(len(df_dev)):\n",
    "    df_dev['commentaire'][i] = get_clean(df_dev['commentaire'][i])\n",
    "    \n",
    "for i in range(len(df_test)):\n",
    "    df_dev['commentaire'][i] = get_clean(df_test['commentaire'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06982c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlèevement des valeurs none après les prétraitement effectués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bdcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_values_train = []\n",
    "for i in range(len(df_train['commentaire'])):\n",
    "    if df_train['commentaire'][i] is np.nan:\n",
    "        non_values_train.append(i)\n",
    "\n",
    "non_values_dev = []\n",
    "for i in range(len(df_dev['commentaire'])):\n",
    "    if df_dev['commentaire'][i] is np.nan:\n",
    "        non_values_dev.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a634d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in non_values_dev:\n",
    "    df_dev = df_dev.drop(index=i, axis = 0)\n",
    "df_dev = df_dev.reset_index(drop=True)\n",
    "\n",
    "for i in non_values_train:\n",
    "    df_train = df_train.drop(index=i, axis = 0)\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train)): #convertir les à des entiers\n",
    "    df_train['note'][i] = (df_train['note'][i])*2\n",
    "    if i < len(df_dev):\n",
    "        df_dev['note'][i] = (df_dev['note'][i])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enlèvement des chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string_dev = df_dev['commentaire'].values.tolist()\n",
    "output_string_dev = []\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "try:\n",
    "    for item in list_string_dev:\n",
    "        output_string_dev.append(item.translate(remove_digits))\n",
    "except:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19169d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string_train = df_train['commentaire'].values.tolist()\n",
    "output_string_train = []\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "try:\n",
    "    for item in list_string_train:\n",
    "        output_string_train.append(item.translate(remove_digits))\n",
    "except:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd83140",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string_test = df_test['commentaire'].values.tolist()\n",
    "output_string_test = []\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "try:\n",
    "    for item in list_string_test:\n",
    "        output_string_test.append(item.translate(remove_digits))\n",
    "except:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543822b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['commentaire'] = output_string_dev\n",
    "df_train['commentaire'] = output_string_train\n",
    "df_test['commentaire'] = output_string_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22690726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['commentaire'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['commentaire'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv(\"C_dev.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"C_train.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"C_train.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
