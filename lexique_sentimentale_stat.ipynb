{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"/Users/eddyakiki/Downloads/archive (1)/sentiment-lexicons/negative_words_fr.txt\", \"r\")\n",
    "\n",
    "data = my_file.read()\n",
    "  \n",
    "data_into_list = data.split(\"\\n\")\n",
    "print(data_into_list)\n",
    "my_file.close()\n",
    "negative_words = data_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"/Users/eddyakiki/Downloads/archive (1)/sentiment-lexicons/positive_words_fr.txt\", \"r\")\n",
    "\n",
    "data = my_file.read()\n",
    "  \n",
    "data_into_list = data.split(\"\\n\")\n",
    "print(data_into_list)\n",
    "my_file.close()\n",
    "positive_words = data_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5446d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "  text = re.sub(\"[%s]\" % re.escape(string.punctuation.replace(\"'\", \"\")), '', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"´\": \"'\", \"°\": \"\", \"€\": \"euros\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"pounds\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':'' ,'à':'a','â':'a','é':'e','è':'e','ê':'e',\n",
    "                 'ë':'e','ç':'c','î':'i','ï':'i','ô':'o','û':'u','ù':'u','ü':'u','ÿ':'y','æ':'ae','œ':'oe','À':'A',\n",
    "                'Â':'A','Ç':'C','É':'E','È':'E','Ê':'E','Ë':'E','Î':'I','Ï':'I','Ô':'O','Û':'U','Ù':'U','Ü':'U','Ÿ':'Y',\n",
    "                'Æ':'AE','Œ':'OE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Transformer les lettres de Majuscules en Minuscules\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r\"[^a-zA-ZàâçéèêëîïôûùüÿæœÀÂÇÉÈÊËÎÏÔÛÙÜŸÆŒ?.!,¿']+\", \" \", text) #garder pour ne pas enlever les charactères français\n",
    "    #text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text) # décommenter pour enlever les charactères français\n",
    "    return text\n",
    "def clean_contractions(text):\n",
    "    specials = [\"’\",\"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # commenter cette ligne pour garder les charactère français''\n",
    "    #text = re.sub(\"[%s]\" % re.escape(string.punctuation.replace(\"'\", \"\")), '', text)\n",
    "    # creation d'un espace entre un mot et une ponctuatuion qui le suit\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "def clean_special_chars(text, punct, mapping):  \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "def remove_space(text):  \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)\n",
    "def spellingCorrector(misspelled):\n",
    "    correction = []\n",
    "    misspelled = nltk.word_tokenize(misspelled)\n",
    "    for word in misspelled:\n",
    "        if re.search(r\"'\", word):\n",
    "            correction.append(word)\n",
    "        else:\n",
    "            corr = spell.correction(word)\n",
    "            if corr != None:\n",
    "                correction.append(corr)\n",
    "            else:\n",
    "                correction.append(word)\n",
    "    return ' '.join(correction)\n",
    "def text_preprocessing_pipeline(text):\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text)\n",
    "    #text = clean_special_chars(text, punct, punct_mapping) # décommenter pour enlever tous les ponctuations et \n",
    "    #charactères français\n",
    "    text = remove_space(text)\n",
    "    #text = spellingCorrector(text) # Computationellement forte de décommenter pas\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a810fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,word in enumerate(positive_words):\n",
    "    positive_words[index] = text_preprocessing_pipeline(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,word in enumerate(negative_words):\n",
    "    negative_words[index] = text_preprocessing_pipeline(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"complete_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(\"dev_complete_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_complete_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()\n",
    "df_train.drop(columns=['index'],inplace=True)\n",
    "df_train['note'] = df_train['note'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae19e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev.reset_index()\n",
    "df_dev.drop(columns=['index'],inplace=True)\n",
    "df_dev['note'] = df_dev['note'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sort_values(by='review_id')\n",
    "df_test = df_test.reset_index()\n",
    "df_test.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f657c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approche Naïve\n",
    "all_scores = []\n",
    "start_time = time.perf_counter()\n",
    "for i in range(len(df_test)):\n",
    "    score = 0\n",
    "    for word in df_test['commentaire'].iloc[i].split():\n",
    "        if word in positive_words:\n",
    "            score+=5\n",
    "        if word in negative_words:\n",
    "            score -= 5\n",
    "    all_scores.append(score)\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"The execution time is: {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e41e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2efa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores calculées sont la polarité une nouvelle colonne ajouté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fe5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['polarity'] = all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df21594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['polarity'] = all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07403aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce491c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv(\"dev_complete_preprocessing_with_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_complete_preprocessing_with_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca126e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_polarity_by_note = df_train.groupby(\"note\")['polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_polarity_by_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0388a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution des classes en attribuant à chaque commentaire la classe pour la quelle son score est le plus proche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =[]\n",
    "start_time_2 = time.perf_counter()\n",
    "for i in range(len(df_test)):\n",
    "    score = 0\n",
    "    for word in df_test['commentaire'].iloc[i].split():\n",
    "        if word in positive_words:\n",
    "            score+=1\n",
    "        if word in negative_words:\n",
    "            score -= 1   \n",
    "    if score < ((mean_polarity_by_note[0]+mean_polarity_by_note[1])/2):\n",
    "        pred.append(0)\n",
    "    elif score < ((mean_polarity_by_note[1]+mean_polarity_by_note[2])/2):\n",
    "        pred.append(1)\n",
    "    elif score < ((mean_polarity_by_note[2]+mean_polarity_by_note[3])/2):\n",
    "        pred.append(2)\n",
    "    elif score < ((mean_polarity_by_note[3]+mean_polarity_by_note[4])/2):\n",
    "        pred.append(3)\n",
    "    elif score < ((mean_polarity_by_note[4]+mean_polarity_by_note[5])/2):\n",
    "        pred.append(4)\n",
    "    elif score < ((mean_polarity_by_note[5]+mean_polarity_by_note[6])/2):\n",
    "        pred.append(5)\n",
    "    elif score < ((mean_polarity_by_note[6]+mean_polarity_by_note[7])/2):\n",
    "        pred.append(6)\n",
    "    elif score < ((mean_polarity_by_note[7]+mean_polarity_by_note[8])/2):\n",
    "        pred.append(7)\n",
    "    elif score < ((mean_polarity_by_note[8]+mean_polarity_by_note[9])/2):\n",
    "        pred.append(8)\n",
    "    elif score > ((mean_polarity_by_note[8]+mean_polarity_by_note[9])/2):\n",
    "        pred.append(9)\n",
    "end_time_2 = time.perf_counter()\n",
    "execution_time_2 = end_time_2 - start_time_2\n",
    "print(f\"The execution time is: {execution_time_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c907f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(df_dev.note.values.tolist(),pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_lexicon_res.txt','w')\n",
    "for item in pred:\n",
    "    file.write(str(item)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Open the file and read the content in a list\n",
    "with open('test_lexicon_res.txt', 'r') as filehandle:\n",
    "    filecontents = filehandle.readlines()\n",
    "    for line in filecontents:\n",
    "        # Remove linebreak which is the last character of the string\n",
    "        curr_res = line[:-1]\n",
    "        # Add item to the list\n",
    "        results.append(curr_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09687927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(data):\n",
    "    with open('results_lexique_naif_with_stp_frsc.txt', 'w') as f:\n",
    "        for row in data:\n",
    "            row_str = \" \".join(str(x) for x in row)\n",
    "            f.write(f\"{row_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c714e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(df_test)):\n",
    "    res.append([df_test['review_id'].iloc[i],str((float(results[i])+1)/2).replace('.',',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e871222",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb574284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
